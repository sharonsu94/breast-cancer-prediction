{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Demo_free_dataset:\n",
    "    def __init__(self, file_path, demo_size):\n",
    "        '''\n",
    "        Splits input csv file into modeling set and demo set\n",
    "        Returns X and y as dataframes in dictionary\n",
    "        Saves demo set to csv\n",
    "        '''\n",
    "        # Read file and create initial X and y\n",
    "        diagnosis_df = pd.read_csv(file_path)\n",
    "\n",
    "        X = diagnosis_df\n",
    "        y = diagnosis_df['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "        # Split modeling set and demp set\n",
    "        X_model, demo_input, y_model, y_demo = train_test_split(X, y, test_size=demo_size)\n",
    "\n",
    "        # Save demo set\n",
    "        # demo_input.drop('Diagnosis', axis=1).to_csv('data/demo_input.csv', index=False)\n",
    "\n",
    "        # Define modeling data set\n",
    "        self.X = X_model\n",
    "        self.y = y_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_columns(dataframe, column_set):\n",
    "    '''\n",
    "    Returns new dataframe based on which columns to drop\n",
    "    from the original dataframe\n",
    "    '''\n",
    "    \n",
    "    # Define which columns to drop\n",
    "    if column_set == 'full':\n",
    "        columns_to_drop = ['ID number', 'Diagnosis']\n",
    "    elif column_set == 'engineered':\n",
    "        columns_to_drop = [\n",
    "            'ID number', 'Diagnosis', \n",
    "            'Area mean', 'Area SE', 'Area worst', \n",
    "            'Concave Points mean', 'Concave Points worst',\n",
    "            'Perimeter mean', 'Perimeter SE', 'Perimeter worst',\n",
    "            'Radius worst',\n",
    "            'Texture worst'\n",
    "        ]\n",
    "            \n",
    "    return dataframe.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Train_test_data():\n",
    "    def __init__(self, X, y, column_set):\n",
    "        '''\n",
    "        Fully format data for the Keras model\n",
    "        '''\n",
    "        \n",
    "        # Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        \n",
    "        # Filter columns for X sets, inherit columns set from above\n",
    "        for dataframe in [X_train, X_test]:\n",
    "            filter_columns(dataframe, column_set)\n",
    "               \n",
    "        # Scale X\n",
    "        X_scaler = StandardScaler().fit(X_train)\n",
    "        \n",
    "        self.X_train_scaled = X_scaler.transform(X_train)\n",
    "        self.X_test_scaled = X_scaler.transform(X_test)\n",
    "        \n",
    "        # Convert y to categorical\n",
    "        self.y_train_categorical = to_categorical(y_train)\n",
    "        self.y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_model(train_test_data, column_set):\n",
    "    '''\n",
    "    Returns accuracy score from keras tensorflow model\n",
    "    '''\n",
    "    if column_set == 'full':\n",
    "        input_size = 30\n",
    "    elif column_set == 'engineered':\n",
    "        input_size = 20\n",
    "\n",
    "    # Create deep neural network model\n",
    "    # Use 2 layers, 6 nodes each\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=6, activation='relu', input_dim=input_size))\n",
    "    model.add(Dense(units=6, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "    # Fit model to training data\n",
    "    model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "        train_test_data.X_train_scaled,\n",
    "        train_test_data.y_train_categorical,\n",
    "        epochs=1000,\n",
    "        shuffle=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    model_loss, model_accuracy = model.evaluate(\n",
    "        train_test_data.X_test_scaled, \n",
    "        train_test_data.y_test_categorical, \n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    return model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up file path and iteration numbers here\n",
    "demo_free_data = Demo_free_dataset('data/diagnosis.csv', 0.02)\n",
    "iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Set: full, Iteration: 0, Time: 14:25:57.399280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ray\\AppData\\Local\\conda\\conda\\envs\\PythonData01\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Set: full, Iteration: 1, Time: 14:26:10.056730\n",
      "Column Set: full, Iteration: 2, Time: 14:26:23.126822\n",
      "Column Set: full, Iteration: 3, Time: 14:26:36.353796\n",
      "Column Set: full, Iteration: 4, Time: 14:26:49.646195\n",
      "Column Set: full, Iteration: 5, Time: 14:27:03.037585\n",
      "Column Set: full, Iteration: 6, Time: 14:27:16.512598\n",
      "Column Set: full, Iteration: 7, Time: 14:27:29.971334\n",
      "Column Set: full, Iteration: 8, Time: 14:27:43.775677\n",
      "Column Set: full, Iteration: 9, Time: 14:27:57.702344\n",
      "Column Set: full, Iteration: 10, Time: 14:28:11.676444\n",
      "Column Set: full, Iteration: 11, Time: 14:28:25.839550\n",
      "Column Set: full, Iteration: 12, Time: 14:28:40.182256\n",
      "Column Set: full, Iteration: 13, Time: 14:28:54.632237\n",
      "Column Set: full, Iteration: 14, Time: 14:29:09.216152\n",
      "Column Set: full, Iteration: 15, Time: 14:29:23.935422\n",
      "Column Set: full, Iteration: 16, Time: 14:29:39.083214\n",
      "Column Set: full, Iteration: 17, Time: 14:29:54.206168\n",
      "Column Set: full, Iteration: 18, Time: 14:30:09.366870\n",
      "Column Set: full, Iteration: 19, Time: 14:30:24.957521\n",
      "Column Set: full, Iteration: 20, Time: 14:30:40.419791\n",
      "Column Set: full, Iteration: 21, Time: 14:30:55.963543\n",
      "Column Set: full, Iteration: 22, Time: 14:31:11.753794\n",
      "Column Set: full, Iteration: 23, Time: 14:31:27.646464\n",
      "Column Set: full, Iteration: 24, Time: 14:31:43.593276\n",
      "Column Set: full, Iteration: 25, Time: 14:31:59.741566\n",
      "Column Set: full, Iteration: 26, Time: 14:32:16.077097\n",
      "Column Set: full, Iteration: 27, Time: 14:32:32.458245\n",
      "Column Set: full, Iteration: 28, Time: 14:32:48.984593\n",
      "Column Set: full, Iteration: 29, Time: 14:33:05.684964\n",
      "Column Set: full, Iteration: 30, Time: 14:33:23.665860\n",
      "Column Set: full, Iteration: 31, Time: 14:33:41.166217\n",
      "Column Set: full, Iteration: 32, Time: 14:33:58.335694\n",
      "Column Set: full, Iteration: 33, Time: 14:34:15.825609\n",
      "Column Set: full, Iteration: 34, Time: 14:34:33.304087\n",
      "Column Set: full, Iteration: 35, Time: 14:34:51.106167\n",
      "Column Set: full, Iteration: 36, Time: 14:35:08.941015\n",
      "Column Set: full, Iteration: 37, Time: 14:35:27.063329\n",
      "Column Set: full, Iteration: 38, Time: 14:35:45.184783\n",
      "Column Set: full, Iteration: 39, Time: 14:36:03.584019\n",
      "Column Set: full, Iteration: 40, Time: 14:36:22.489507\n",
      "Column Set: full, Iteration: 41, Time: 14:36:41.245753\n",
      "Column Set: full, Iteration: 42, Time: 14:37:00.054952\n",
      "Column Set: full, Iteration: 43, Time: 14:37:19.282074\n",
      "Column Set: full, Iteration: 44, Time: 14:37:38.430436\n",
      "Column Set: full, Iteration: 45, Time: 14:37:57.733748\n",
      "Column Set: full, Iteration: 46, Time: 14:38:17.186812\n",
      "Column Set: full, Iteration: 47, Time: 14:38:36.670145\n",
      "Column Set: full, Iteration: 48, Time: 14:38:56.417946\n",
      "Column Set: full, Iteration: 49, Time: 14:39:16.223892\n",
      "Column Set: engineered, Iteration: 0, Time: 14:39:36.307317\n",
      "Column Set: engineered, Iteration: 1, Time: 14:39:56.523609\n",
      "Column Set: engineered, Iteration: 2, Time: 14:40:17.113237\n",
      "Column Set: engineered, Iteration: 3, Time: 14:40:38.198020\n",
      "Column Set: engineered, Iteration: 4, Time: 14:40:58.945403\n",
      "Column Set: engineered, Iteration: 5, Time: 14:41:20.060180\n",
      "Column Set: engineered, Iteration: 6, Time: 14:41:41.219838\n",
      "Column Set: engineered, Iteration: 7, Time: 14:42:02.398974\n",
      "Column Set: engineered, Iteration: 8, Time: 14:42:23.974903\n",
      "Column Set: engineered, Iteration: 9, Time: 14:42:45.561689\n",
      "Column Set: engineered, Iteration: 10, Time: 14:43:07.457443\n",
      "Column Set: engineered, Iteration: 11, Time: 14:43:29.745073\n",
      "Column Set: engineered, Iteration: 12, Time: 14:43:51.993266\n",
      "Column Set: engineered, Iteration: 13, Time: 14:44:14.584676\n",
      "Column Set: engineered, Iteration: 14, Time: 14:44:37.156605\n",
      "Column Set: engineered, Iteration: 15, Time: 14:45:00.137705\n",
      "Column Set: engineered, Iteration: 16, Time: 14:45:23.364326\n",
      "Column Set: engineered, Iteration: 17, Time: 14:45:46.886853\n",
      "Column Set: engineered, Iteration: 18, Time: 14:46:10.910398\n",
      "Column Set: engineered, Iteration: 19, Time: 14:46:35.010866\n",
      "Column Set: engineered, Iteration: 20, Time: 14:46:59.735204\n",
      "Column Set: engineered, Iteration: 21, Time: 14:47:24.327107\n",
      "Column Set: engineered, Iteration: 22, Time: 14:47:48.791102\n",
      "Column Set: engineered, Iteration: 23, Time: 14:48:13.643650\n",
      "Column Set: engineered, Iteration: 24, Time: 14:48:38.444948\n",
      "Column Set: engineered, Iteration: 25, Time: 14:49:03.461220\n",
      "Column Set: engineered, Iteration: 26, Time: 14:49:28.563456\n",
      "Column Set: engineered, Iteration: 27, Time: 14:49:53.720279\n",
      "Column Set: engineered, Iteration: 28, Time: 14:50:19.305916\n",
      "Column Set: engineered, Iteration: 29, Time: 14:50:45.461022\n",
      "Column Set: engineered, Iteration: 30, Time: 14:51:11.392620\n",
      "Column Set: engineered, Iteration: 31, Time: 14:51:37.841486\n",
      "Column Set: engineered, Iteration: 32, Time: 14:52:04.449376\n",
      "Column Set: engineered, Iteration: 33, Time: 14:52:34.411443\n",
      "Column Set: engineered, Iteration: 34, Time: 14:53:01.137895\n",
      "Column Set: engineered, Iteration: 35, Time: 14:53:28.111748\n",
      "Column Set: engineered, Iteration: 36, Time: 14:53:55.161508\n",
      "Column Set: engineered, Iteration: 37, Time: 14:54:22.932560\n",
      "Column Set: engineered, Iteration: 38, Time: 14:54:50.371142\n",
      "Column Set: engineered, Iteration: 39, Time: 14:55:18.898340\n",
      "Column Set: engineered, Iteration: 40, Time: 14:55:47.075794\n",
      "Column Set: engineered, Iteration: 41, Time: 14:56:15.710023\n",
      "Column Set: engineered, Iteration: 42, Time: 14:56:44.031947\n",
      "Column Set: engineered, Iteration: 43, Time: 14:57:12.836375\n",
      "Column Set: engineered, Iteration: 44, Time: 14:57:41.799929\n",
      "Column Set: engineered, Iteration: 45, Time: 14:58:10.893731\n",
      "Column Set: engineered, Iteration: 46, Time: 14:58:40.365545\n",
      "Column Set: engineered, Iteration: 47, Time: 14:59:10.018266\n",
      "Column Set: engineered, Iteration: 48, Time: 14:59:39.991741\n",
      "Column Set: engineered, Iteration: 49, Time: 15:00:10.008524\n"
     ]
    }
   ],
   "source": [
    "# Compare accuracy with full features and with engineered features\n",
    "for column_set in ['full', 'engineered']:\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    \n",
    "    # Run x times to collect accuracy scores\n",
    "    for i in range(0, iterations):\n",
    "        \n",
    "        # Progress check\n",
    "        timestamp = datetime.strftime(datetime.now(), '%H:%M:%S.%f')\n",
    "        print(f'Column Set: {column_set}, Iteration: {i}, Time: {timestamp}')\n",
    "        \n",
    "        # Randomly split train test data and format for modeling\n",
    "        tt_data = Train_test_data(demo_free_data.X, demo_free_data.y, column_set)\n",
    "        # Train model, test, and record accuracy\n",
    "        accuracy_scores.append(train_test_model(tt_data, column_set))\n",
    "    \n",
    "    # Export to csv\n",
    "    df = pd.DataFrame({'accuracy': accuracy_scores})\n",
    "    df.to_csv(f'data/{column_set}_features_accuracy_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_accuracies = pd.read_csv('data/full_features_accuracy_scores.csv')\n",
    "engineered_accuracies = pd.read_csv('data/engineered_features_accuracy_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = full_accuracies['accuracy'].tolist()\n",
    "engineered_list = engineered_accuracies['accuracy'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.DataFrame({\n",
    "    'full': full_list,\n",
    "    'engineered': engineered_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engineered</th>\n",
       "      <th>full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.957842</td>\n",
       "      <td>0.966475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.014795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.913669</td>\n",
       "      <td>0.928058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.944245</td>\n",
       "      <td>0.956835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.967626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.976619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.992806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       engineered       full\n",
       "count   50.000000  50.000000\n",
       "mean     0.957842   0.966475\n",
       "std      0.017259   0.014795\n",
       "min      0.913669   0.928058\n",
       "25%      0.944245   0.956835\n",
       "50%      0.956835   0.967626\n",
       "75%      0.971223   0.976619\n",
       "max      0.992806   0.992806"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
