{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Demo_free_dataset:\n",
    "    def __init__(self, file_path, demo_size):\n",
    "        '''\n",
    "        Splits input csv file into modeling set and demo set\n",
    "        Returns X and y as dataframes in dictionary\n",
    "        Saves demo set to csv\n",
    "        '''\n",
    "        # Read file and create initial X and y\n",
    "        diagnosis_df = pd.read_csv(file_path)\n",
    "\n",
    "        X = diagnosis_df\n",
    "        y = diagnosis_df['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "        # Split modeling set and demp set\n",
    "        X_model, demo_input, y_model, y_demo = train_test_split(X, y, test_size=demo_size)\n",
    "\n",
    "        # Save demo set\n",
    "        demo_input.drop('Diagnosis', axis=1).to_csv('data/demo_input.csv', index=False)\n",
    "\n",
    "        # Define modeling data set\n",
    "        self.X = X_model\n",
    "        self.y = y_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_columns(dataframe, column_set):\n",
    "    '''\n",
    "    Returns new dataframe based on which columns to drop\n",
    "    from the original dataframe\n",
    "    '''\n",
    "    \n",
    "    # Define which columns to drop\n",
    "    if column_set == 'full':\n",
    "        columns_to_drop = ['ID number', 'Diagnosis']\n",
    "    elif column_set == 'engineered':\n",
    "        columns_to_drop = [\n",
    "            'ID number', 'Diagnosis', \n",
    "            'Area mean', 'Area SE', 'Area worst', \n",
    "            'Concave Points mean', 'Concave Points worst',\n",
    "            'Perimeter mean', 'Perimeter SE', 'Perimeter worst',\n",
    "            'Radius worst',\n",
    "            'Texture worst'\n",
    "        ]\n",
    "            \n",
    "    return dataframe.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Train_test_data():\n",
    "    def __init__(self, X, y, column_set):\n",
    "        '''\n",
    "        Fully format data for the Keras model\n",
    "        '''\n",
    "        \n",
    "        # Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        \n",
    "        # Filter columns for X sets, inherit columns set from above\n",
    "        for dataframe in [X_train, X_test]:\n",
    "            filter_columns(dataframe, column_set)\n",
    "               \n",
    "        # Scale X\n",
    "        X_scaler = StandardScaler().fit(X_train)\n",
    "        \n",
    "        self.X_train_scaled = X_scaler.transform(X_train)\n",
    "        self.X_test_scaled = X_scaler.transform(X_test)\n",
    "        \n",
    "        # Convert y to categorical\n",
    "        self.y_train_categorical = to_categorical(y_train)\n",
    "        self.y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_model(train_test_data, column_set):\n",
    "    '''\n",
    "    Returns accuracy score from keras tensorflow model\n",
    "    '''\n",
    "    if column_set == 'full':\n",
    "        input_size = 30\n",
    "    elif column_set == 'engineered':\n",
    "        input_size = 20\n",
    "\n",
    "    # Create deep neural network model\n",
    "    # Use 2 layers, 6 nodes each\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=6, activation='relu', input_dim=input_size))\n",
    "    model.add(Dense(units=6, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "    # Fit model to training data\n",
    "    model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "        train_test_data.X_train_scaled,\n",
    "        train_test_data.y_train_categorical,\n",
    "        epochs=1000,\n",
    "        shuffle=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    model_loss, model_accuracy = model.evaluate(\n",
    "        train_test_data.X_test_scaled, \n",
    "        train_test_data.y_test_categorical, \n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    return model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up file path and iteration numbers here\n",
    "demo_free_data = Demo_free_dataset('data/diagnosis.csv', 0.02)\n",
    "iterations = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Set: full, Iteration: 0, Time: 13:39:25.840642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ray\\AppData\\Local\\conda\\conda\\envs\\PythonData01\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Set: full, Iteration: 1, Time: 13:39:38.785595\n",
      "Column Set: full, Iteration: 2, Time: 13:39:52.214324\n",
      "Column Set: full, Iteration: 3, Time: 13:40:05.558959\n",
      "Column Set: full, Iteration: 4, Time: 13:40:19.206430\n",
      "Column Set: full, Iteration: 5, Time: 13:40:32.963989\n",
      "Column Set: full, Iteration: 6, Time: 13:40:46.826826\n",
      "Column Set: full, Iteration: 7, Time: 13:41:00.841910\n",
      "Column Set: full, Iteration: 8, Time: 13:41:14.994682\n",
      "Column Set: full, Iteration: 9, Time: 13:41:29.287349\n",
      "Column Set: full, Iteration: 10, Time: 13:41:43.697038\n",
      "Column Set: full, Iteration: 11, Time: 13:41:58.408016\n",
      "Column Set: full, Iteration: 12, Time: 13:42:13.148389\n",
      "Column Set: full, Iteration: 13, Time: 13:42:27.890324\n",
      "Column Set: full, Iteration: 14, Time: 13:42:42.812488\n",
      "Column Set: full, Iteration: 15, Time: 13:42:57.908644\n",
      "Column Set: full, Iteration: 16, Time: 13:43:13.288348\n",
      "Column Set: full, Iteration: 17, Time: 13:43:30.241993\n",
      "Column Set: full, Iteration: 18, Time: 13:43:45.967195\n",
      "Column Set: full, Iteration: 19, Time: 13:44:01.842602\n",
      "Column Set: full, Iteration: 20, Time: 13:44:17.576685\n",
      "Column Set: full, Iteration: 21, Time: 13:44:33.362849\n",
      "Column Set: full, Iteration: 22, Time: 13:44:49.308560\n",
      "Column Set: full, Iteration: 23, Time: 13:45:05.391909\n",
      "Column Set: full, Iteration: 24, Time: 13:45:21.642509\n",
      "Column Set: full, Iteration: 25, Time: 13:45:38.247333\n",
      "Column Set: full, Iteration: 26, Time: 13:45:54.903811\n",
      "Column Set: full, Iteration: 27, Time: 13:46:11.748845\n",
      "Column Set: full, Iteration: 28, Time: 13:46:28.482598\n",
      "Column Set: full, Iteration: 29, Time: 13:46:45.324919\n",
      "Column Set: engineered, Iteration: 0, Time: 13:47:02.307069\n",
      "Column Set: engineered, Iteration: 1, Time: 13:47:19.580011\n",
      "Column Set: engineered, Iteration: 2, Time: 13:47:38.069063\n",
      "Column Set: engineered, Iteration: 3, Time: 13:47:56.228349\n",
      "Column Set: engineered, Iteration: 4, Time: 13:48:14.035128\n",
      "Column Set: engineered, Iteration: 5, Time: 13:48:31.691501\n",
      "Column Set: engineered, Iteration: 6, Time: 13:48:49.479240\n",
      "Column Set: engineered, Iteration: 7, Time: 13:49:07.654622\n",
      "Column Set: engineered, Iteration: 8, Time: 13:49:25.927175\n",
      "Column Set: engineered, Iteration: 9, Time: 13:49:44.084628\n",
      "Column Set: engineered, Iteration: 10, Time: 13:50:02.634223\n",
      "Column Set: engineered, Iteration: 11, Time: 13:50:21.326378\n",
      "Column Set: engineered, Iteration: 12, Time: 13:50:39.968825\n",
      "Column Set: engineered, Iteration: 13, Time: 13:50:58.853993\n",
      "Column Set: engineered, Iteration: 14, Time: 13:51:17.882475\n",
      "Column Set: engineered, Iteration: 15, Time: 13:51:37.094961\n",
      "Column Set: engineered, Iteration: 16, Time: 13:51:56.251676\n",
      "Column Set: engineered, Iteration: 17, Time: 13:52:16.021740\n",
      "Column Set: engineered, Iteration: 18, Time: 13:52:36.042904\n",
      "Column Set: engineered, Iteration: 19, Time: 13:52:55.856507\n",
      "Column Set: engineered, Iteration: 20, Time: 13:53:15.810801\n",
      "Column Set: engineered, Iteration: 21, Time: 13:53:35.967260\n",
      "Column Set: engineered, Iteration: 22, Time: 13:53:56.238227\n",
      "Column Set: engineered, Iteration: 23, Time: 13:54:16.859909\n",
      "Column Set: engineered, Iteration: 24, Time: 13:54:37.552267\n",
      "Column Set: engineered, Iteration: 25, Time: 13:54:58.782752\n",
      "Column Set: engineered, Iteration: 26, Time: 13:55:20.377522\n",
      "Column Set: engineered, Iteration: 27, Time: 13:55:42.031291\n",
      "Column Set: engineered, Iteration: 28, Time: 13:56:04.994304\n",
      "Column Set: engineered, Iteration: 29, Time: 13:56:26.931569\n"
     ]
    }
   ],
   "source": [
    "# Compare accuracy with full features and with engineered features\n",
    "for column_set in ['full', 'engineered']:\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    \n",
    "    # Run x times to collect accuracy scores\n",
    "    for i in range(0, iterations):\n",
    "        \n",
    "        # Progress check\n",
    "        timestamp = datetime.strftime(datetime.now(), '%H:%M:%S.%f')\n",
    "        print(f'Column Set: {column_set}, Iteration: {i}, Time: {timestamp}')\n",
    "        \n",
    "        # Randomly split train test data and format for modeling\n",
    "        tt_data = Train_test_data(demo_free_data.X, demo_free_data.y, column_set)\n",
    "        # Train model, test, and record accuracy\n",
    "        accuracy_scores.append(train_test_model(tt_data, column_set))\n",
    "    \n",
    "    # Export to csv\n",
    "    df = pd.DataFrame({'accuracy': accuracy_scores})\n",
    "    df.to_csv(f'data/{column_set}_features_accuracy_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.strftime(datetime.now(), '%H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
